CS122 Assignment 3 - Join Optimization - Design Document
========================================================

A:  Logistics
-------------

A1.  List your team name and the people who worked on this assignment.

     BBB

     Ryan Batterman
     Alex Bello
     Ronnel Boettcher

A2.  Specify the tag name and commit-hash of the Git version you are
     submitting for your assignment.  (You can list the commit hashes
     of your repository tags with this command:  git show-ref --tags)

     Tag name:     <tag>
     Commit hash:  <hash>

A3.  Specify any late tokens you are applying to this assignment, or
     "none" if no late tokens.

     none

A4.  Briefly describe what parts of the assignment each teammate focused on.

    A lot of the work was done by sitting and coding together. That said, we focused
    on some specific things.

    Ronnel implemented the collectDetails and makeLeafPlan functions. In other 
    words collection of conjunctions and leaf nodes and preparation of leaf plan nodes.
    Ryan implemented optimal join planning and makePlan
    Bello implemented trivial projections for inner joins and some debugging/testing.

B:  Generating Optimal Joins
----------------------------

B1.  Briefly describe how you generate an "optimal" access to a base table.
     
     We create a FileScanNode and pass whichever conjuncts are applicable to
     the base table.

B2.  Briefly describe how you decide when it is acceptable to push
     conjuncts down through an outer join.

     If the outer join is a left outer join, the conjuncts applicable to
     the left fromClause are pushed down to the construction of the left
     fromClause's plan node. The same is true for right outer joins. This
     is based on the equivalence rule described in the assignment.

B3.  The planner in this assignment is still somewhat limited; for example,
     we can't push conjuncts down into subqueries.  Using the stores schema,
     write an example SQL query that includes a subquery, where it would be
     beneficial to push a conjunct down into the subquery.  (Your planner
     obviously doesn't need to perform this optimization.)

     SELECT * FROM (SELECT * FROM cities,stores) t WHERE 
        t.city_name = 'New York';

     In this case, pushing the conjunct inside the inner cross join would
     obviously improve performance.

B4.  Enumerate the situations where you call prepare() on plans being
     generated.  Since this operation is somewhat expensive, do you
     see any ways to reduce the number of times you call prepare() in
     your implementation?

     - After adding conjuncts to the where expression in makeLeafPlan
     using PlanUtils.addPredicate().
     - Before calling getSchema() on a node to prepare its schema.
     - fromClause is prepared in makePlan() before node construction to
     support calls to fromClause.getPreparedSchema() during plan node
     construction.
     - After construction of the plan node before returning in makePlan().
     - In generateOptimalJoin() to compute the cpu cost.

     To reduce the number of calls, only call when: computing something
     about the plan (CPU cost, schema, etc), or when modifying the 
     schema of the plan.

B5.  In what situations can you end up with unused conjuncts after
     planning joins.  Illustrate by giving an example SQL statement
     that would have unused conjuncts after join planning, again using
     the stores schema.  Then, describe a strategy for where/how these
     left-over conjuncts should be applied in the plan.

     SELECT state_id, AVG(population) AS avg_pop FROM cities 
        GROUP BY state_id HAVING avg_pop > 1000000;

     In this example, the conjunct "avg_pop > 1000000" refers to a 
     column name (avg_pop) that does not exist while leaf nodes are
     being joined together, but is constructed after grouping and
     aggregation is handled. We can apply these leftover conjuncts
     after grouping and aggregation by adding a simple filter node
     passing the conjuncts as an expression.

C:  Costing SQL Queries
-----------------------

After you have loaded the stores-28K.sql data and have analyzed all of
the tables in that schema, run the following explain operations and paste
the output from your planner (excluding debug output!).

If there is anything unusual or non-obvious about your output, feel free
to write explanatory notes after your output.

C1.  EXPLAIN SELECT * FROM cities WHERE population > 5000000;

Explain Plan:
    FileScan[table:  CITIES, pred:  CITIES.POPULATION > 5000000] cost=[tuples=254.0, tupSize=23.8, cpuCost=254.0, blockIOs=1]

Estimated 254.000000 tuples with average size 23.787401
Estimated number of block IOs:  1


*------------------------------------------------------------------------*
C2.  EXPLAIN SELECT store_id FROM stores, cities 
            WHERE stores.city_id = cities.city_id AND
            cities.population > 1000000;

Explain Plan:
    Project[values:  [STORES.STORE_ID]] cost=[tuples=2000.0, tupSize=36.8, cpuCost=512254.0, blockIOs=5]
        NestedLoops[pred:  STORES.CITY_ID == CITIES.CITY_ID] cost=[tuples=2000.0, tupSize=36.8, cpuCost=510254.0, blockIOs=5]
            FileScan[table:  CITIES, pred:  CITIES.POPULATION > 1000000] cost=[tuples=254.0, tupSize=23.8, cpuCost=254.0, blockIOs=1]
            FileScan[table:  STORES] cost=[tuples=2000.0, tupSize=13.0, cpuCost=2000.0, blockIOs=4]

Estimated 2000.000000 tuples with average size 36.787399
Estimated number of block IOs:  5



*------------------------------------------------------------------------*
C3.  EXPLAIN SELECT store_id FROM stores JOIN
        (SELECT city_id FROM cities WHERE population > 1000000) AS big_cities 
        ON stores.city_id = big_cities.city_id;

Explain Plan:
    Project[values:  [STORES.STORE_ID]] cost=[tuples=2000.0, tupSize=36.8, cpuCost=512508.0, blockIOs=5]
        NestedLoops[pred:  STORES.CITY_ID == BIG_CITIES.CITY_ID] cost=[tuples=2000.0, tupSize=36.8, cpuCost=510508.0, blockIOs=5]
            Rename[resultTableName=BIG_CITIES] cost=[tuples=254.0, tupSize=23.8, cpuCost=508.0, blockIOs=1]
                Project[values:  [CITIES.CITY_ID]] cost=[tuples=254.0, tupSize=23.8, cpuCost=508.0, blockIOs=1]
                    FileScan[table:  CITIES, pred:  CITIES.POPULATION > 1000000] cost=[tuples=254.0, tupSize=23.8, cpuCost=254.0, blockIOs=1]
            FileScan[table:  STORES] cost=[tuples=2000.0, tupSize=13.0, cpuCost=2000.0, blockIOs=4]

Estimated 2000.000000 tuples with average size 36.787399
Estimated number of block IOs:  5




*------------------------------------------------------------------------*
C4.  EXPLAIN SELECT store_id, property_costs FROM stores, cities, states
        WHERE stores.city_id = cities.city_id AND
        cities.state_id = states.state_id AND
        state_name = 'Oregon' AND property_costs > 500000;

Explain Plan:
    Project[values:  [STORES.STORE_ID, STORES.PROPERTY_COSTS]] cost=[tuples=2000.0, tupSize=52.5, cpuCost=525259.1, blockIOs=6]
        NestedLoops[pred:  STORES.CITY_ID == CITIES.CITY_ID] cost=[tuples=2000.0, tupSize=52.5, cpuCost=523259.0, blockIOs=6]
            NestedLoops[pred:  CITIES.STATE_ID == STATES.STATE_ID] cost=[tuples=254.0, tupSize=39.5, cpuCost=13259.0, blockIOs=2]
                FileScan[table:  STATES, pred:  STATES.STATE_NAME == 'Oregon'] cost=[tuples=51.0, tupSize=15.7, cpuCost=51.0, blockIOs=1]
                FileScan[table:  CITIES] cost=[tuples=254.0, tupSize=23.8, cpuCost=254.0, blockIOs=1]
            FileScan[table:  STORES, pred:  STORES.PROPERTY_COSTS > 500000] cost=[tuples=2000.0, tupSize=13.0, cpuCost=2000.0, blockIOs=4]

Estimated 2000.000122 tuples with average size 52.454067
Estimated number of block IOs:  6


E:  Extra Credit [OPTIONAL]
---------------------------

If you implemented any extra-credit tasks for this assignment, describe
them here.  The description should be like this, with stuff in "<>" replaced.
(The value i starts at 1 and increments...)

E<i>:  <one-line description>

     <brief summary of what you did, including the specific classes that
     we should look at for your implementation>

     <brief summary of test-cases that demonstrate/exercise your extra work>

F:  Feedback [OPTIONAL]
-----------------------

These questions are optional, and they obviously won't affect your grade
in any way (including if you hate everything about the assignment and
databases in general, or Donnie and the TAs in particular).

NOTE:  If you wish to give anonymous feedback, a similar survey will be
       made available on the Moodle.  

F1.  How many hours total did your team spend on this assignment?
     (That is, the sum of each teammate's time spent on the assignment.)

F2.  What parts of the assignment were most time-consuming?

F3.  Which parts of the assignment did you particularly enjoy?

F4.  Which parts did you particularly dislike?

F5.  Do you have any suggestions for how future versions of the
     assignment can be improved?
